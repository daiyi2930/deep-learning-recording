{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting data with + indicating (y = 1) examples and o indicating (y = 0) examples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2nKCMDOztv4/3t+hsQ3pv7YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x77e06d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File 'ex2data1.txt' contains data in 3 columns\n",
    "# Columns 1 and 2 are exam scores\n",
    "# Column 3 is the label\n",
    "\n",
    "f = open('ex2data1.txt', 'r')\n",
    "x1_list = []\n",
    "x2_list = []\n",
    "y_list = []\n",
    "\n",
    "for line in f:\n",
    "    x1_str, x2_str, y_str = line.split(',')\n",
    "    x1_list.append(float(x1_str))\n",
    "    x2_list.append(float(x2_str))\n",
    "    y_list.append(int(y_str))\n",
    "\n",
    "# Let's now plot the data\n",
    "    \n",
    "print('Plotting data with + indicating (y = 1) examples and o indicating (y = 0) examples')\n",
    "\n",
    "for i in range(0,len(y_list)):\n",
    "    if y_list[i] == 1:\n",
    "        plt.plot(x1_list[i],x2_list[i],'b+',linewidth=0)\n",
    "    else:\n",
    "        plt.plot(x1_list[i],x2_list[i],'ro',linewidth=0)\n",
    "plt.xlabel('Exam 1 score')\n",
    "plt.ylabel('Exam 2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x1 = np.matrix(x1_list).reshape(len(x1_list),1)\n",
    "x2 = np.matrix(x2_list).reshape(len(x2_list),1)\n",
    "\n",
    "max_x1 = np.amax(x1, axis=0)\n",
    "max_x2 = np.amax(x2, axis=0)\n",
    "min_x1 = np.amin(x1, axis=0)\n",
    "min_x2 = np.amin(x2, axis=0)\n",
    "mean_x1 = np.average(x1, axis=0)\n",
    "mean_x2 = np.average(x2, axis=0)\n",
    "\n",
    "for i in range(0,len(y_list)):\n",
    "    x1[i,0] = (x1[i,0] - mean_x1) / (max_x1 - min_x1)\n",
    "    x2[i,0] = (x2[i,0] - mean_x2) / (max_x2 - min_x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.matrix(y_list).reshape(len(y_list),1)\n",
    "X = np.c_[x1,x2]\n",
    "\n",
    "m = len(y_list)\n",
    "nn_input_dim = 2\n",
    "nn_output_dim = 2\n",
    "nn_hidden_dim = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "W1 = np.random.random((nn_input_dim, nn_hidden_dim)) * 2.0 - 1.0\n",
    "b1 = np.zeros((1, nn_hidden_dim))\n",
    "W2 = np.random.random((nn_hidden_dim, nn_output_dim)) * 2.0 - 1.0\n",
    "b2 = np.zeros((1, nn_output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:  [[ 0.65151171 -0.38198799 -0.93355731  0.51767817 -0.6703484 ]\n",
      " [ 0.82935139 -0.15985876 -0.05400091  0.24187882 -0.05106153]]\n",
      "b1:  [[ 0.  0.  0.  0.  0.]]\n",
      "W2:  [[ 0.3795989  -0.07144333]\n",
      " [-0.39295786  0.41482622]\n",
      " [ 0.93374748 -0.74741437]\n",
      " [-0.80421196  0.28453994]\n",
      " [ 0.2902257  -0.8437296 ]]\n",
      "b2:  [[ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print('W1: ',W1)\n",
    "print('b1: ',b1)\n",
    "print('W2: ',W2)\n",
    "print('b2: ',b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X          m x nn_input_dim\n",
    "# W1, dW1    nn_input_dim x nn_hidden_dim\n",
    "# b1, db1    1 x nn_hidden_dim\n",
    "# s1         m x nn_hidden_dim\n",
    "# h1         m x nn_hidden_dim\n",
    "# W2, dW2    nn_hidden_dim x nn_output_dim\n",
    "# b2, db2    1 x nn_output_dim\n",
    "# s2         m x nn_output_dim\n",
    "# esp_score  m x nn_output_dim\n",
    "# h          m x nn_output_dim\n",
    "# delta2     m x nn_output_dim\n",
    "# delta1     m x nn_hidden_dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions at iteration  0  :  0.74\n",
      "Cross entropy loss:  73.9142069156\n",
      "Accuracy of predictions at iteration  100  :  0.71\n",
      "Cross entropy loss:  73.4190759997\n",
      "Accuracy of predictions at iteration  200  :  0.63\n",
      "Cross entropy loss:  72.7467228312\n",
      "Accuracy of predictions at iteration  300  :  0.54\n",
      "Cross entropy loss:  72.4733115782\n",
      "Accuracy of predictions at iteration  400  :  0.53\n",
      "Cross entropy loss:  71.6697877794\n",
      "Accuracy of predictions at iteration  500  :  0.53\n",
      "Cross entropy loss:  70.2705033028\n",
      "Accuracy of predictions at iteration  600  :  0.56\n",
      "Cross entropy loss:  69.4182748745\n",
      "Accuracy of predictions at iteration  700  :  0.63\n",
      "Cross entropy loss:  69.255436843\n",
      "Accuracy of predictions at iteration  800  :  0.66\n",
      "Cross entropy loss:  69.2775371365\n",
      "Accuracy of predictions at iteration  900  :  0.67\n",
      "Cross entropy loss:  69.3005161051\n",
      "Accuracy of predictions at iteration  1000  :  0.69\n",
      "Cross entropy loss:  69.3103864776\n",
      "Accuracy of predictions at iteration  1100  :  0.69\n",
      "Cross entropy loss:  69.314025031\n",
      "Accuracy of predictions at iteration  1200  :  0.69\n",
      "Cross entropy loss:  69.3152777247\n",
      "Accuracy of predictions at iteration  1300  :  0.7\n",
      "Cross entropy loss:  69.3156438487\n",
      "Accuracy of predictions at iteration  1400  :  0.7\n",
      "Cross entropy loss:  69.3156834526\n",
      "Accuracy of predictions at iteration  1500  :  0.7\n",
      "Cross entropy loss:  69.3156092495\n",
      "Accuracy of predictions at iteration  1600  :  0.7\n",
      "Cross entropy loss:  69.315503253\n",
      "Accuracy of predictions at iteration  1700  :  0.7\n",
      "Cross entropy loss:  69.315396633\n",
      "Accuracy of predictions at iteration  1800  :  0.71\n",
      "Cross entropy loss:  69.315300285\n",
      "Accuracy of predictions at iteration  1900  :  0.71\n",
      "Cross entropy loss:  69.315216987\n",
      "Accuracy of predictions at iteration  2000  :  0.71\n",
      "Cross entropy loss:  69.3151463747\n",
      "Accuracy of predictions at iteration  2100  :  0.71\n",
      "Cross entropy loss:  69.3150870044\n",
      "Accuracy of predictions at iteration  2200  :  0.71\n",
      "Cross entropy loss:  69.3150371993\n",
      "Accuracy of predictions at iteration  2300  :  0.71\n",
      "Cross entropy loss:  69.3149953781\n",
      "Accuracy of predictions at iteration  2400  :  0.71\n",
      "Cross entropy loss:  69.314960164\n",
      "Accuracy of predictions at iteration  2500  :  0.71\n",
      "Cross entropy loss:  69.3149304018\n",
      "Accuracy of predictions at iteration  2600  :  0.71\n",
      "Cross entropy loss:  69.3149051395\n",
      "Accuracy of predictions at iteration  2700  :  0.71\n",
      "Cross entropy loss:  69.3148835998\n",
      "Accuracy of predictions at iteration  2800  :  0.71\n",
      "Cross entropy loss:  69.3148651494\n",
      "Accuracy of predictions at iteration  2900  :  0.72\n",
      "Cross entropy loss:  69.314849273\n",
      "Accuracy of predictions at iteration  3000  :  0.72\n",
      "Cross entropy loss:  69.3148355506\n",
      "Accuracy of predictions at iteration  3100  :  0.72\n",
      "Cross entropy loss:  69.3148236383\n",
      "Accuracy of predictions at iteration  3200  :  0.72\n",
      "Cross entropy loss:  69.3148132543\n",
      "Accuracy of predictions at iteration  3300  :  0.72\n",
      "Cross entropy loss:  69.3148041661\n",
      "Accuracy of predictions at iteration  3400  :  0.72\n",
      "Cross entropy loss:  69.3147961815\n",
      "Accuracy of predictions at iteration  3500  :  0.72\n",
      "Cross entropy loss:  69.3147891407\n",
      "Accuracy of predictions at iteration  3600  :  0.72\n",
      "Cross entropy loss:  69.3147829105\n",
      "Accuracy of predictions at iteration  3700  :  0.72\n",
      "Cross entropy loss:  69.3147773791\n",
      "Accuracy of predictions at iteration  3800  :  0.72\n",
      "Cross entropy loss:  69.3147724524\n",
      "Accuracy of predictions at iteration  3900  :  0.72\n",
      "Cross entropy loss:  69.314768051\n",
      "Accuracy of predictions at iteration  4000  :  0.72\n",
      "Cross entropy loss:  69.3147641075\n",
      "Accuracy of predictions at iteration  4100  :  0.72\n",
      "Cross entropy loss:  69.3147605644\n",
      "Accuracy of predictions at iteration  4200  :  0.72\n",
      "Cross entropy loss:  69.3147573726\n",
      "Accuracy of predictions at iteration  4300  :  0.72\n",
      "Cross entropy loss:  69.3147544901\n",
      "Accuracy of predictions at iteration  4400  :  0.72\n",
      "Cross entropy loss:  69.3147518806\n",
      "Accuracy of predictions at iteration  4500  :  0.72\n",
      "Cross entropy loss:  69.3147495128\n",
      "Accuracy of predictions at iteration  4600  :  0.72\n",
      "Cross entropy loss:  69.3147473595\n",
      "Accuracy of predictions at iteration  4700  :  0.72\n",
      "Cross entropy loss:  69.3147453971\n",
      "Accuracy of predictions at iteration  4800  :  0.72\n",
      "Cross entropy loss:  69.3147436051\n",
      "Accuracy of predictions at iteration  4900  :  0.72\n",
      "Cross entropy loss:  69.3147419655\n",
      "Accuracy of predictions at iteration  5000  :  0.72\n",
      "Cross entropy loss:  69.3147404626\n",
      "Accuracy of predictions at iteration  5100  :  0.72\n",
      "Cross entropy loss:  69.3147390824\n",
      "Accuracy of predictions at iteration  5200  :  0.72\n",
      "Cross entropy loss:  69.3147378127\n",
      "Accuracy of predictions at iteration  5300  :  0.72\n",
      "Cross entropy loss:  69.3147366428\n",
      "Accuracy of predictions at iteration  5400  :  0.72\n",
      "Cross entropy loss:  69.314735563\n",
      "Accuracy of predictions at iteration  5500  :  0.72\n",
      "Cross entropy loss:  69.314734565\n",
      "Accuracy of predictions at iteration  5600  :  0.72\n",
      "Cross entropy loss:  69.3147336411\n",
      "Accuracy of predictions at iteration  5700  :  0.72\n",
      "Cross entropy loss:  69.3147327847\n",
      "Accuracy of predictions at iteration  5800  :  0.72\n",
      "Cross entropy loss:  69.3147319896\n",
      "Accuracy of predictions at iteration  5900  :  0.72\n",
      "Cross entropy loss:  69.3147312506\n",
      "Accuracy of predictions at iteration  6000  :  0.72\n",
      "Cross entropy loss:  69.3147305627\n",
      "Accuracy of predictions at iteration  6100  :  0.72\n",
      "Cross entropy loss:  69.3147299217\n",
      "Accuracy of predictions at iteration  6200  :  0.72\n",
      "Cross entropy loss:  69.3147293236\n",
      "Accuracy of predictions at iteration  6300  :  0.72\n",
      "Cross entropy loss:  69.314728765\n",
      "Accuracy of predictions at iteration  6400  :  0.72\n",
      "Cross entropy loss:  69.3147282426\n",
      "Accuracy of predictions at iteration  6500  :  0.72\n",
      "Cross entropy loss:  69.3147277535\n",
      "Accuracy of predictions at iteration  6600  :  0.72\n",
      "Cross entropy loss:  69.3147272952\n",
      "Accuracy of predictions at iteration  6700  :  0.72\n",
      "Cross entropy loss:  69.3147268652\n",
      "Accuracy of predictions at iteration  6800  :  0.72\n",
      "Cross entropy loss:  69.3147264614\n",
      "Accuracy of predictions at iteration  6900  :  0.72\n",
      "Cross entropy loss:  69.3147260819\n",
      "Accuracy of predictions at iteration  7000  :  0.72\n",
      "Cross entropy loss:  69.3147257248\n",
      "Accuracy of predictions at iteration  7100  :  0.72\n",
      "Cross entropy loss:  69.3147253886\n",
      "Accuracy of predictions at iteration  7200  :  0.72\n",
      "Cross entropy loss:  69.3147250717\n",
      "Accuracy of predictions at iteration  7300  :  0.72\n",
      "Cross entropy loss:  69.3147247728\n",
      "Accuracy of predictions at iteration  7400  :  0.72\n",
      "Cross entropy loss:  69.3147244906\n",
      "Accuracy of predictions at iteration  7500  :  0.72\n",
      "Cross entropy loss:  69.3147242239\n",
      "Accuracy of predictions at iteration  7600  :  0.72\n",
      "Cross entropy loss:  69.3147239718\n",
      "Accuracy of predictions at iteration  7700  :  0.72\n",
      "Cross entropy loss:  69.3147237332\n",
      "Accuracy of predictions at iteration  7800  :  0.72\n",
      "Cross entropy loss:  69.3147235072\n",
      "Accuracy of predictions at iteration  7900  :  0.72\n",
      "Cross entropy loss:  69.3147232931\n",
      "Accuracy of predictions at iteration  8000  :  0.72\n",
      "Cross entropy loss:  69.31472309\n",
      "Accuracy of predictions at iteration  8100  :  0.72\n",
      "Cross entropy loss:  69.3147228972\n",
      "Accuracy of predictions at iteration  8200  :  0.72\n",
      "Cross entropy loss:  69.3147227142\n",
      "Accuracy of predictions at iteration  8300  :  0.72\n",
      "Cross entropy loss:  69.3147225402\n",
      "Accuracy of predictions at iteration  8400  :  0.72\n",
      "Cross entropy loss:  69.3147223748\n",
      "Accuracy of predictions at iteration  8500  :  0.72\n",
      "Cross entropy loss:  69.3147222175\n",
      "Accuracy of predictions at iteration  8600  :  0.72\n",
      "Cross entropy loss:  69.3147220676\n",
      "Accuracy of predictions at iteration  8700  :  0.72\n",
      "Cross entropy loss:  69.3147219249\n",
      "Accuracy of predictions at iteration  8800  :  0.72\n",
      "Cross entropy loss:  69.3147217889\n",
      "Accuracy of predictions at iteration  8900  :  0.72\n",
      "Cross entropy loss:  69.3147216591\n",
      "Accuracy of predictions at iteration  9000  :  0.72\n",
      "Cross entropy loss:  69.3147215353\n",
      "Accuracy of predictions at iteration  9100  :  0.72\n",
      "Cross entropy loss:  69.3147214171\n",
      "Accuracy of predictions at iteration  9200  :  0.72\n",
      "Cross entropy loss:  69.3147213042\n",
      "Accuracy of predictions at iteration  9300  :  0.72\n",
      "Cross entropy loss:  69.3147211963\n",
      "Accuracy of predictions at iteration  9400  :  0.72\n",
      "Cross entropy loss:  69.3147210931\n",
      "Accuracy of predictions at iteration  9500  :  0.72\n",
      "Cross entropy loss:  69.3147209943\n",
      "Accuracy of predictions at iteration  9600  :  0.72\n",
      "Cross entropy loss:  69.3147208998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions at iteration  9700  :  0.72\n",
      "Cross entropy loss:  69.3147208093\n",
      "Accuracy of predictions at iteration  9800  :  0.72\n",
      "Cross entropy loss:  69.3147207226\n",
      "Accuracy of predictions at iteration  9900  :  0.72\n",
      "Cross entropy loss:  69.3147206395\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "num_passes = 10000\n",
    "alpha = 0.0001\n",
    "\n",
    "for i in range(0, num_passes):\n",
    " \n",
    "    # Forward propagation\n",
    "    s1 = X.dot(W1) + b1\n",
    "    h1 = np.tanh(s1)\n",
    "    s2 = h1.dot(W2) + b2\n",
    "    exp_scores = np.exp(s2)\n",
    "    h = exp_scores / np.sum(exp_scores, axis=1) # softmax\n",
    "    \n",
    "    if (i%100 == 0) :\n",
    "        predict = [1 if k >= 0.5 else 0 for k in h[:,1]]\n",
    "        print('Accuracy of predictions at iteration ', i, ' : ', np.sum(np.equal(predict,y_list))/len(y_list))\n",
    "        loss = np.sum(-np.log(h[range(m), y])) * 1.0/m\n",
    "        print('Cross entropy loss: ', loss)\n",
    "    \n",
    "    # Backpropagation\n",
    "    delta2 = h\n",
    "    delta2[range(m), y] -= 1\n",
    "    dW2 = (h1.T).dot(delta2)\n",
    "    db2 = np.sum(delta2, axis=0)\n",
    "    delta1 = np.multiply(delta2.dot(W2.T), (1 - np.power(h1, 2)))\n",
    "    dW1 = np.dot(X.T, delta1)\n",
    "    db1 = np.sum(delta1, axis=0)\n",
    "        \n",
    "    # Gradient descent parameter update\n",
    "    W1 += -alpha * dW1\n",
    "    b1 += -alpha * db1\n",
    "    W2 += -alpha * dW2\n",
    "    b2 += -alpha * db2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:  [[ 0.36952334 -0.25137726 -0.41965606  0.2317469  -0.30691329]\n",
      " [ 0.45780755 -0.08282693 -0.04929     0.13995282 -0.03682894]]\n",
      "b1:  [[ 4.95065424  4.90465128  4.92602178 -4.93842297 -4.94337618]]\n",
      "W2:  [[ 48.68935535  48.30847146]\n",
      " [ 46.92266457  47.88192838]\n",
      " [ 48.66428744  47.26253281]\n",
      " [-49.42119292 -48.62604502]\n",
      " [-48.51042316 -49.7906836 ]]\n",
      "b2:  [[ 49.83088688  50.16911312]]\n",
      "FINAL Accuracy of predictions:  0.72\n",
      "FINAL Cross entropy loss:  69.3147205599\n"
     ]
    }
   ],
   "source": [
    "# Calculate the error on the training set based on recent weights\n",
    "s1 = X.dot(W1) + b1\n",
    "h1 = np.tanh(s1)\n",
    "s2 = h1.dot(W2) + b2\n",
    "exp_scores = np.exp(s2)\n",
    "h = exp_scores / np.sum(exp_scores, axis=1) # softmax\n",
    "\n",
    "# Calculate error for the given weights\n",
    "print('W1: ',W1)\n",
    "print('b1: ',b1)\n",
    "print('W2: ',W2)\n",
    "print('b2: ',b2)\n",
    "predict = [1 if k >= 0.5 else 0 for k in h[:,1]]\n",
    "print('FINAL Accuracy of predictions: ', np.sum(np.equal(predict,y_list))/len(y_list))\n",
    "loss = np.sum(-np.log(h[range(m), y])) * 1.0/m\n",
    "print('FINAL Cross entropy loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a student with scores 45 and 85, we predict an admission probability of  0.92238782768\n"
     ]
    }
   ],
   "source": [
    "# Make prediction\n",
    "Example = np.matrix([45, 85]).reshape(1,2)\n",
    "s1 = Example.dot(W1) + b1\n",
    "h1 = np.tanh(s1)\n",
    "s2 = h1.dot(W2) + b2\n",
    "exp_scores = np.exp(s2)\n",
    "h = exp_scores / np.sum(exp_scores, axis=1) # softmax\n",
    "print('For a student with scores 45 and 85, we predict an admission probability of ', h[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
